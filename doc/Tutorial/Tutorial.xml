<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.2//EN"
"http://www.oasis-open.org/docbook/xml/4.2/docbookx.dtd">
<book xmlns:xi="http://www.w3.org/2003/XInclude">
  <bookinfo>
    <title>Synopsis Tutorial</title>

    <releaseinfo>Version 0.9</releaseinfo>
    <author>
      <firstname>Stefan</firstname>
      <surname>Seefeld</surname>
    </author>
  </bookinfo>

  <chapter id="intro">
    <title>Introduction</title>
    <para>
      Synopsis is a source code introspection tool. It provides parsers for a variety
      of programming languages (C, C++, Python, IDL), and generates internal representations
      of varying granularity. The only <emphasis>stable</emphasis> representation, which
      is currently used among others to generate documentation, is an Abstract Syntax Tree.
    </para>
    <para>
      This tutorial is focussed on the AST and the concepts around it. Other representations
      are presently being worked on, notably in relation to the C++ parser. To learn more
      about those (Parse Tree, Symbol Table, etc.) see the 
      <ulink url="../DevGuide/index.html">Developer's Guide</ulink>.
    </para>
    <section>
      <title>Inspecting code</title>

      <!-- Talk about the problem domain:
         code documentation, software metrics, etc. -->

      <para></para>
    </section>

    <section id="ir">
      <title>Internal representations</title>

      <para>Synopsis parses source code into a variety of <emphasis>internal representations</emphasis> (IRs),
        which then are manipulated in various ways, before some output (such as a cross-referenced API
        documentation) is generated by an appropriate <emphasis>formatter</emphasis>.</para>
      <para>At the core of Synopsis are a set of programing-language independent IRs which
        all <emphasis>parser frontends</emphasis> generate. These parsers use other IRs internally,
        which eventually get translated into the common representations.</para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/ir.svg" format="SVG" scale="80" />
        </imageobject>

        <imageobject>
          <imagedata fileref="images/ir.png" format="PNG" />
        </imageobject>
      </mediaobject>
      <para>For details about the AST, see <xref linkend="ast" /></para>
      <para>At this time, the C++ frontend's IRs are not yet accessible through python, though they 
        eventually will be, making it possible to use Synopsis as a source-to-source compiler. To learn
        more about the evolving C &amp; C++ parser and its IRs, see the 
        <ulink url="../DevGuide/index.html">Developer's Guide</ulink>.</para>

    </section>

    <section>
      <title>Documenting source code</title>
      <para>Being read and understood is at least as important for source code
        as it is for it to be processed by a computer. Humans have to maintain
        the code, i.e. fix bugs, add features, etc.</para>
      <para>Therefor, typically, code is annotated in some form in that adds
        explanation if it isn't self-explanatory. While comments are often
        used to simply disable the execution of a particular chunk of code, some
        comments are specifically addressed at readers to explain what the 
        surrounding code does. While some languages (e.g. Python) have built-in
        support for <emphasis>doc-strings</emphasis>, in other languages ordinary
        comments are used.</para>
      <para>Typically, comments are marked up in a specific way to discriminate
        documentation from ordinary comments. Further the content of such comments
        may contain markup for a particular formatting (say, embedded HTML).</para>
      <example><title>Typical C++ code documentation</title>
        <caption>
          <para>C++ may contain a mix of comments, some representing documentation.
          </para>
        </caption>
        <screen>
//! A friendly function.
void greet()
{
  // FIXME: Use gettext for i18n
  std::cout &lt;&lt; "hello world !" &lt;&lt; std::endl;
}
        </screen>
      </example>

      <para>In Synopsis all declarations may be annotated. C and C++ parsers,
        for example, will store comments preceding a given declaration in
        that declaration's <varname>annotations</varname> dictionary under the 
        key <constant>comments</constant>. Later these comments may be translated 
        into documentation (stored under the key <constant>doc</constant>), which 
        may be formatted once the final document is generated.</para>
      <para>Translating comments into doc-strings involves the removal of comment
        markers (such as the <code>//!</code> above), as well as the handling of
        processing instructions that may be embedded in comments, too.</para>
      <para>For languages such as Python such a translation isn't necessary,
        as the language has built-in support for documentation, and thus the
        parser itself can generate the 'doc' annotations.</para>
      <example><title>Python code documentation</title>
        <caption>
          <para>Python has support for documentation built into the language.</para>
        </caption>
        <screen>
>>> def greet():
...     """The greet function prints out a famous message."""
...     print 'hello world !'
...
>>>help(greet)


Help on function greet in module __main__:

greet()
    The greet function prints out a famous message.
        </screen>
      </example>
    </section>

    <section>
      <title>The synopsis processing pipeline</title>

      <para>Synopsis provides a large number of <emphasis>processor</emphasis>
        types that all generate or operate on data extracted from source code.
        Parsers parse source code from a variety of languages, linkers combine
        multiple ASTs, resolving cross-references between symbols, and formatters
        format the AST into a variety of output media.</para>

      <para>They all share a common design, to make it easy to combine them
        into pipelines, add custom processors. For more documentation about
        this architecture, see <xref linkend="pipeline" />.</para>
    </section>
  </chapter>

  <chapter id="using">
    <title>Using the synopsis tool</title>
    <para>In this section we are going to explore the possibilities
      to generate documentation from source code. We will demonstrate
      how to use synopsis standalone as well as in conjunction with
      existing build systems. Further, we will see how to adapt
      synopsis to your coding and commenting style, as well as how
      to generate the output in a format and style that fulfills
      your needs.</para>
    <section id="options">
      <title>Option handling</title>
      <para>As discussed earlier, there is a variety of processors available in the
        Synopsis distribution. There are a number of parsers (for IDL, Python, and C++,
        and C), some formatters (HTML is probably the most popular
        one, but others such as Docbook, Texinfo, or Dot may be useful, too),
        and a number of linker processors.</para>
      <para>Synopsis takes short options (e.g. <option>-h</option>) as well as
        long options (e.g. <option>--help</option>). To see the full list of toplevel
        options, use <command>synopsis -h</command>.</para>
      <para>By means of the <option>-W</option> option you can pass arguments down to
        particular processors that are run. For example, 
        <command>synopsis -p Cxx -Wp,--base_path=../src/</command>
        instructs synopsis to use the <type>Cxx</type> parser, and then passes the
        <varname>base_path</varname> argument to it.</para>
      <para>To find out about what parameters a processor defines, use the <option>--help</option>
        option. For example <command>synopsis -p Cxx --help</command>
        will tell us how to use the Cxx parser. To pass these options to the Cxx parser,
        simply append them via the <option>-Wp</option> option, and they will be forwarded.
        The <option>-Wp</option> accepts either of two option forms.</para>
      <para>The <varname>--option=value</varname> form expects <varname>value</varname> to 
        be a string, and passes that to the <varname>option</varname> parameter. Omitting 
        <varname>value</varname> makes its value default to the python <constant>True</constant>
        literal.</para>
      <para>Alternatively, you can use the <varname>option=value</varname> form (i.e. omitting
        the dashes), which will result in <varname>value</varname> to be interpreted as a
        python expression. This is useful if the expected parameter type is a python type such
        as a list. However, care has to be taken to properly quote the value in that case to
        prevent the shell to expand it.</para>
      <para>If we want to generate a (UML) class diagram, we could for example run 
        <programlisting>synopsis -f Dot -Wf,--title="class diagram" -Wf,--format=ps \
          -Wf,hide_operations=False,hide_attributes=False \
          -o Paths.ps Paths.syn</programlisting>
      </para>
      <para>But passing options via the command line has its limits, both, in terms of
        usability, as well as for the robustness of the interface (all data have to be
        passed as strings !). Therefor, for any tasks demanding more flexibility a
        scripting interface is provided, which will be discussed in the next chapter.
      </para>
    </section>
    <section id="parsing">
      <title>Parsing source code</title>
      <para>The synopsis executable is a convenience frontend
        to the larger Synopsis framework consisting of AST-related
        types as well as processor classes.</para>
      <para>While the full power of synopsis is available through
        scripting (see <xref linkend="scripting" />), the most frequent
        use cases are captured in the <command>synopsis</command> executable.
      </para>
      <para>Let's assume a simple header file, containing some declarations:</para>
      <para>
        <programlisting><xi:include href="examples/Paths/src/Path.h" parse="text"/>
        </programlisting>
      </para>
      <para>Process this with
        <programlisting>synopsis -p Cxx -f HTML -o Paths Path.h</programlisting>
        to generate an html document in the directory specified using the 
        <option>-o</option> option, i.e. <filename>Paths</filename>.
      </para>
      <para>
        The above represents the simplest way to use <command>synopsis</command>.
        A simple command is used to parse a source file and to generate a document
        from it. The parser to be used is selected using the <option>-p</option>
        option, and the formatter with the <option>-f</option> option.
      </para>
      <para>If no formatter is specified, synopsis dumps its 
        <link linkend="ir">internal representation</link> to the specified output file.
        Similarly, if no parser is specified, the input is interpreted as an IR dump.
        Thus, the processing can be split into multiple synopsis invocations.</para>
      <para>
        Each processor (including parsers and formatters) provides a number of
        parameters that can be set from the command line. For example the Cxx parser
        has a parameter <varname>base_path</varname> to specify a prefix to be stripped
        off of file names as they are stored in synopsis' internal representation.
        Parser-specific options can be given that are passed through to the parser
        processor. To pass such an option, use the <code>-Wp,</code> prefix.
        For example, to set the parser's <varname>base_path</varname> option, use
        <programlisting>synopsis -p Cxx -Wp,-base_path=&lt;prefix&gt; -f HTML -o Paths Path.h</programlisting>
      </para>
      <para>To set a formatter-specific option use <code>-Wf,</code>, and so on.
        Use the <option>--help</option> to find out about options available for a
        particular processor, e.g.
        <programlisting>synopsis --help</programlisting>
        or
        <programlisting>synopsis -p Cxx --help</programlisting>
      </para>
    </section>
    <section id="comments">
      <title>Using comments for documentation</title>
      <para>Until now the generated document didn't contain any of the text from
        comments in the source code. To do that the comments have to be translated
        first. This translation consists of a filter that picks up a particular kind
        of comment, for example only lines starting with "//.", or javadoc-style
        comments such as "/**...*/", as well as some translator that converts the
        comments into actual documentation, possibly using some inline markup, such
        as Javadoc or ReST.</para>
      <para>The following source code snippet contains java-style comments, with
        javadoc-style markup. Further, an embedded processing instruction wants some
        declarations to be grouped.
        <programlisting><xi:include href="examples/Paths/src/Bezier.h" parse="text"/>
        </programlisting>
      </para>
      <para>
        The right combination of comment processing options for this code would be:
        <programlisting>synopsis -p Cxx --cfilter=java --translate=javadoc -lComments.Grouper ...</programlisting>
        The <option>--cfilter</option> option allows to specify a filter to select
        document comments, and the <option>--translate</option> option sets the kind of markup
        to expect. The <option>-l</option> option is somewhat more generic. It is a <emphasis>linker</emphasis>
        to which (almost) arbitrary post-processors can be attached. Here we pass the <type>Comments.Grouper</type>
        processor that injects <type>Group</type> nodes into the IR that cause the grouped declarations to
        be documented together.
      </para>
    </section>
  </chapter>

  <chapter id="scripting">
    <title>Scripting and extending synopsis</title>

    <para>Often it isn't enough to provide textual options to the synopsis tool.
      The processors that are at the core of the synopsis framework are highly
      configurable. They can be passed simple string / integer / boolean type
      parameters, but some of them are also composed of objects that could be
      passed along as parameters.</para>

    <para>While synopsis provides a lot of such building blocks already, you may
      want to extend them by subclassing your own.</para>
    
    <para>In all these cases scripting is a much more powerful way to let
      synopsis do what you want. This chapter explains the basic design
      of the framework, and demonstrates how to write scripts using the
      built-in building blocks as well as user extensions</para>

    <section id="ast">
      <title>The AST</title>

      <para>At the core of synopsis is a representation of
        the source code to be analyzed called an abstract syntax
        tree (AST). Language specific syntax gets translated into
        and abstract tree of statements, annotated with all the necessary
        metadata to recover the important details during further processing.</para>

      <para>At this time only one particular type of statements is translated
        into an AST: declarations. This can be declarations of types, functions,
        variables, etc. Attached to a declaration is a set of comments that was
        found in the source code before the declaration. It is thus possible
        to provide other metadata (such as code documentation) as part of these
        comments. A variety of comment processors exist to extract such metadata
        from comments.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/ast.svg" format="SVG" scale="80" />
        </imageobject>

        <imageobject>
          <imagedata fileref="images/ast.png" format="PNG" />
        </imageobject>
      </mediaobject>
    </section>

    <section id="processor">
      <title>The Processor class</title>

      <!-- Talk about the Processor class design -->

      <para>The Processor class is at the core of the synopsis framework. It
      is the basic building block out of which processing pipelines can be
      composed.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/processor.svg" format="SVG" scale="80" />
        </imageobject>

        <imageobject>
          <imagedata fileref="images/processor.png" format="PNG" />
        </imageobject>
      </mediaobject>

      <para>The requirement that processors can be composed into a pipeline
      has some important consequences for its design. The process method takes
      an ast argument, which it will operate on, and then return. It is this
      ast that forms the backbone of the pipeline, as it is passed along from
      one processor to the next. Additionally, parameters may be passed to the
      processor, such as input and output.</para>

      <programlisting>def process(self, ast, **keywords):

  self.set_parameters(keywords)
  self.ast = self.merge_input(ast)

  # do the work here...

  return self.output_and_return_ast()</programlisting>

      <para>Depending on the nature of the processor, it may parse the input
      file as source code, or simply read it in from a persistent state. In
      any case, the result of the input reading is merged in with the existing
      ast.</para>

      <programlisting>def process(self, ast, **keywords):

  self.set_parameters(keywords)

  for file in self.input:
    self.ast.merge(self.parse(file))

  return self.output_and_return_ast()</programlisting>

      <para>Similarly with the output: if an output parameter is defined, the
      ast may be stored in that file before it is returned. Or, if the
      processor is a formatter, the output parameter may indicate the file /
      directory name to store the formatted output in.</para>

      <programlisting>def process(self, ast, **keywords):
  
  self.set_parameters(keywords)
  self.ast = self.merge_input(ast)
  
  self.format(self.output)
  
  return set.ast</programlisting>
    </section>

    <section id="pipeline">
      <title>Composing a pipeline</title>

      <para>With such a design, processors can simply be chained together:</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/pipeline.svg" format="SVG" scale="80" />
        </imageobject>

        <imageobject>
          <imagedata fileref="images/pipeline.png" format="PNG" />
        </imageobject>
      </mediaobject>

      <para>A parser creates an AST, which is passed to the linker (creating 
        a table of contents on the fly) which passes it further down to a
        formatter.</para>

      <programlisting>parser = ...
linker = ...
formatter = ...
ast = AST()
ast = parser.process(ast, input=[&#39;source.hh&#39;])
ast = linker.process(ast)
ast = formatter.process(ast, output=&#39;html&#39;)</programlisting>

      <para>And, to be a little bit more scalable, and to allow the use of
      dependency tracking build tools such as make, the intermediate asts can
      be persistet into files. Thus, the above pipeline is broken up into multiple
      pipelines, where the 'output' parameter of the parser is used to 
      point to ast stores, and the 'input' parameter of the linker/formatter 
      pipeline then contains a list of these ast store files.</para>

      <mediaobject>
        <imageobject>
          <imagedata fileref="images/pipelines.svg" format="SVG" scale="80" />
        </imageobject>

        <imageobject>
          <imagedata fileref="images/pipelines.png" format="PNG" />
        </imageobject>
      </mediaobject>
      <para>Parse <filename>source1.hh</filename> and write the ast to <filename>source1.syn</filename>:</para>
      <programlisting>parser.process(AST(), input = [&#39;source1.hh&#39;], output = &#39;source1.syn&#39;)</programlisting>
      <para>Parse <filename>source2.hh</filename> and write the ast to <filename>source2.syn</filename>:</para>
      <programlisting>parser.process(AST(), input = [&#39;source2.hh&#39;], output = &#39;source2.syn&#39;)</programlisting>
      <para>Read in <filename>source1.syn</filename> and <filename>source2.syn</filename>, then link and format 
        into the <filename>html</filename> directory:</para>
      <programlisting>formatter.process(linker.process(AST(), input = [&#39;source1.syn&#39;, &#39;source2.syn&#39;]), output = &#39;html&#39;)</programlisting>
    </section>

    <section id="script">
      <title>Writing your own synopsis script</title>

      <para>The synopsis framework provides a function <function>process</function> 
        that lets you declare and expose processors as commands so they can be 
        used per command line:
        <programlisting><xi:include href="examples/Paths/html/synopsis.py" parse="text"/>
        </programlisting>
      </para>
      <para>With such a script <filename>synopsis.py</filename> it is possible
        to call
        <programlisting>python synopsis.py cxx_ssd --output=Bezier.syn Bezier.h
        </programlisting>
        to do the same as in <xref linkend="using"/>, but with much more
        flexibility. Let's have a closer look at how this script works:</para>
       <section id="importing">
         <title>Importing all desired processors</title>
         <para>As every conventional python script, the first thing to do is
           to pull in all the definitions that are used later on, in our case
           the definition of the <function>process</function> function, together
           with a number of predefined processors.
         </para>
       </section>
       <section id="composing">
         <title>Composing new processors</title>
         <para>As outlined in <xref linkend="pipeline"/>, processors can be
           composed into pipelines, which are themselfs new (composite) processors.
           Synopsis provides a <type>Composite</type> type for convenient pipeline
           construction. Its constructor takes a list of processors that the
           process method will iterate over.
         </para>
       </section>
       <section id="extending">
         <title>Defining new processors</title>
         <para>New processors can be defined by deriving from <type>Processor</type>
           or any of its subclasses. As outlined in <xref linkend="processor"/>, 
           it has only to respect the semantics of the <function>process</function>
           method.</para>
       </section>
       <section id="process">
         <title>Exposing the commands</title>
         <para>With all these new processrs defined, they need to be made accessible
           to be called per command line. That is done with the <function>process</function>
           function. It sets up a dictionary of named processors, with which the script
           can be invoked as
          <programlisting>python synopsis.py joker
          </programlisting>
          which will invoke the joker's <function>process</function> method with
          any argument that was provided passed as a named value (keyword).
         </para>
       </section>
    </section>
  </chapter>
  <chapter>
    <title>Processor design</title>
    <section id="python-parser">
      <title>Python Parser</title>
    </section>
    <section id="idl-parser">
      <title>IDL Parser</title>
      <para>The IDL parser parses CORBA IDL.</para>
    </section>
    <section id="cpp-parser">
      <title>Cpp Parser</title>
      <para>The Cpp parser preprocesses C and C++ files. As any normal preprocessor,
        it will generate a file suitable as input for a C or C++ parser, i.e. it 
        processes include and macro statements. However, it will store the encountered
        preprocessor directives in the AST for further analysis.</para>
      <para>As the list of included files may grow rather large, there exist two mechanisms
        to restrict the number of files for which information is retained. The <type>main_file_only</type>
        parameter is used to indicate that only the top-level file being parsed should be included.
        The <type>base_path</type> parameter, on the other hand, will restrict the number files if
        <type>main_file_only</type> is set to <type>False</type>. In this case, the <type>base_path</type>
        is used as a prefix, and only those file whose name starts with that prefix are marked as 
        <type>main</type>.
      </para>
      <para>For each included file, a <type>SourceFile</type> object is created and added
        to the parent's <type>Include</type> list. Further, all macro declarations, as well
        as macro calls, are recorded. While most useful in conjunction with the C and Cxx processors,
        these data can be of use stand-alone, too. For example consider a tool that reports file
        dependencies based on <type>#include</type> statements. The Dot formatter (see <xref linkend="dot-formatter"/>)
        can generate a file dependency graph from the Cpp processor output alone:
      </para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/Files.png" format="PNG" />
        </imageobject>
      </mediaobject>
      <para>Particular care has been taken in order to emulate system compilers, as these
        all provide their own sets of macros, include paths, etc. Thus, the Cpp parser can
        be trained to understand these compiler-specific settings.</para>
      <para>For details about the parameters see <xref linkend="Cpp-Parser-ref"/>.</para>
    </section>
    <section id="cc-parser">
      <title>C Parser</title>
      <para>The C parser parses C.</para>
    </section>
    <section id="cxx-parser">
      <title>Cxx Parser</title>
      <para>The Cxx parser parses C++. If the <type>preprocess</type> parameter is set, it will
        call the preprocessor (see <xref linkend="cpp-parser"/>). Its main purpose is to generate
        an AST containing all declarations. However, it can store more detailed information about
        the source code to be used in conjunction with the HTML parser to generate a cross-referenced
        view of the code. The <type>syntax_prefix</type> and <type>xref_prefix</type> parameters are
        used to indicate directories within which to store information about the source files being
        parsed. For a view of the processing pipeline to generate cross-referenced code see
        <xref linkend="cross-referencing"/>.</para>
    </section>
    <section id="linker">
      <title>Linker</title>
      <para>The Linker recursively traverses the AST using the Visitor
        pattern, and replaces any duplicate types with their originals, and
        removes duplicate declarations. References to the removed declarations
        are replaced with a reference to the original. This action is largely
        unncessary due to the -m flags, but can still be useful in some
        situations, such as when you have nested classes defined in separate
        files. It also converts AST.Modules into AST.MetaModules, which list all
        the files a module is defined in.</para>
    </section>
    <section id="comment-parsers">
      <title>Comment Parsers</title>
    </section>
    <section id="dump-formatter">
      <title>Dump Formatter</title>
      <para>The Dump formatter's main goal is to provide a format
        that is as close to the AST tree, is easily browsable to the
        naked eye, and provides the means to do validation or other
        analysis.</para>
      <para>It generates an xml tree that can be browsed via mozilla (it
        uses a stylesheet for convenient display), or it can be analyzed
        with some special tools using xpath expressions.</para>
      <para>It is used right now for all unit tests.</para>
    </section>
    <section id="ascii-formatter">
      <title>ASCII Formatter</title>
      <para>The ASCII formatter attempts to output the AST in a format that is
      suitable for recompilation, or close to. You can use this to check
      that your code and comments are getting parsed correctly, or out of
      interest to see the structure of the AST after Linking. Like the DUMP
      formatter, this is mostly of use for debugging.</para>
    </section>
    <section id="docbook-formatter">
      <title>Docbook Formatter</title>
    </section>
    <section id="dot-formatter">
      <title>Dot Formatter</title>
      <para>The Dot formatter can generate graphs for various types and output formats.
        Among the supported output formats are <type>png</type>, <type>svg</type>, and
        <type>html</type>.</para>
      <para>A typical use is the generation of UML class (inheritance and aggregation)
        diagrams:</para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/Classes3.png" format="PNG" />
        </imageobject>
      </mediaobject>
      <para>But it can also be used to generate a graphical representation of file
        inclusions:</para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/Files.png" format="PNG" />
        </imageobject>
      </mediaobject>
    </section>
    <section id="html-formatter">
      <title>HTML Formatter</title>
      <para>The HTML formatter generates html output. It is designed 
        in a modular way, to let users customize in much detail how
        to format the data. All output is organized by a set of 
        <emphasis>views</emphasis>, which highlight different aspects of data.
        Some views show the file / directory layout, others group declarations by 
        scopes, or provide an annotated (and cross-referenced) source view.</para>
      <para>By default the formatter generates its output using frames. The views
        are formatter parameters. <varname>index</varname> is a list of views that
        fill the upper-left index frame. <varname>detail</varname> is a list of
        views for the lower-left detail frame, and <varname>content</varname>
        sets all the views for the main content frame.</para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/html-screenshot.png" format="PNG"
                     align="center" scale="100" />
        </imageobject>
      </mediaobject>
      <para>When the <varname>index</varname> and <varname>detail</varname> arguments
        are empty lists, non-framed html will be generated.</para>
      <para>Here are the most important <type>View</type> types:</para>
      <variablelist>
        <varlistentry>
          <term>Scope</term>
          <listitem>
            <para>The most important view for documentation purposes is doubtless the
              <type>Scope</type> view. It presents all declaration in a given scope,
              together with a number of references to other views if appropriate.
            </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>InheritanceGraph</term>
          <listitem>
            <para>A UML-like inheritance diagram for all classes.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>NameIndex</term>
          <listitem>
            <para>A global index of all declared names (macros, variables, types, ...)</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Source</term>
          <listitem>
            <para>A cross-referenced view of a source file.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>XRef</term>
          <listitem>
            <para>A listing of symbols with links to their documentation, definition, and reference.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>FileDetails</term>
          <listitem>
            <para>Shows details about a given file, such as what other files are included, what declarations it contains, etc.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Directory</term>
          <listitem>
            <para>Presents a directory (of source files). This is typically used
              in conjunction with the Source view above.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>FileTree</term>
          <listitem>
            <para>A javascript-based file tree view suitable for the index frame
              for navigation.</para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ModuleTree</term>
          <listitem>
            <para>A javascript-based module tree view suitable for the index frame
              for navigation.</para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
    <section id="sxr-formatter">
      <title>SXR Formatter</title>
      <para>The SXR formatter is a variant of the HTML formatter. However, as its
        focus is not so much documentation as code navigation, there are a number
        of important differences. Its default set of views is different, and instead
        of displaying listings of all identifiers on static html, it loads a database
        of (typed) identifiers and provides an interface to query them.</para>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/sxr-screenshot.png" format="PNG" 
                     align="center" scale="100" />
        </imageobject>
      </mediaobject>
      <para>It is to be used with an http server, either a default http server
        such as apache in conjunction with the <emphasis>sxi.cgi</emphasis> script
        that is part of Synopsis, or by using the <emphasis>sxr-server</emphasis>
        program. The latter performs better, as the database is kept in-process,
        while in case of sxi.cgi it needs to be reloaded on each query.</para>
    </section>
  </chapter>
  <chapter>
    <title>Extending synopsis with the C++ API</title>
    <section id="cxx-api">
      <para>The C++ API tries to get as close as possible to the python API 
        for the AST and Type module (see <xref linkend="ast" />). Two factories,
        an <type>ASTKit</type> and a <type>TypeKit</type> allow the creation of
        all the AST objects.</para>
      <para></para>
    </section>
  </chapter>
  <appendix id="executable">
    <title>Description of program options for the synopsis executable</title>
    <title>The synopsis executable</title>
    <para>The synopsis executable is a little convenience frontend
      to the larger Synopsis framework consisting of AST related
      types as well as processor classes.</para>
    <para>While the full power of synopsis is available through
      scripting (see <xref linkend="scripting" />), it is possible
      to quickly generate simple documentation by means of an
      easy-to-use executable, that is nothing more but a little
      script with some extra command line argument parsing.</para>
    <para>This tool has three processor types it can call:</para>
    <variablelist>
      <varlistentry>
        <term>Parser</term>
        <listitem>
          <para>A processor that will parse source code into an
            internal abstract syntax tree (AST). Various Parsers
            have a variety of parameters to control how exactly
            they do that.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Linker</term>
        <listitem>
          <para>A processor that will remove duplicate symbols,
            forward declarations, and apply any number of AST
            manipulations you want. The user typically specifies
            what sub-processors to load to run from the linker.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Formatter</term>
        <listitem>
          <para>A processor that generates some form of formatted
            output from an existing AST, typically html, docbook xml,
            or class graphs. Other formatters exist to assist debugging,
            such as a <type>List</type> formatter that prints specific
            aspects of the IR to stdout, or a <type>Dump</type> formatter
            that writes the IR to an xml file, useful for unit testing.</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <para>You can run synopsis with a single processor, for example
      to parse a C++ file <filename>source.hh</filename> and store 
      the AST into a file <filename>source.syn</filename>, or you can
      combine it directly with linker and or formatter to generate
      the output you want in a single call.</para>
    <para>While the document generation in a single call is convenient,
      for larger projects it is much more sensible to integrate the
      document generation into existing build systems and let the build
      system itself manage the dependencies between the intermediate files
      and the source files.</para>
    <para>For example, a typical Makefile fragment that contains the rules
      to generate documentation out of multiple source files may look like
      this:</para>
    <programlisting>
      hdr := $(wildcard *.h)
      syn := $(patsubst %.h, %.syn, $(hdr))

      html: $(syn)
          synopsis -f HTML -o $@ $&lt;

      %.syn: %.h
          synopsis -p Cxx -I../include -o $@ $&lt;
    </programlisting>
    <para>Here is a listing of all available options:</para>
    <variablelist>
      <varlistentry>
        <term>-h</term>
        <term>--help</term>
        <listitem>
          <para>print out help message</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-V</term>
        <term>--version</term>
        <listitem>
          <para>print out version info and exit</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-v</term>
        <term>--verbose</term>
        <listitem>
          <para>operate verbosely</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-d</term>
        <term>--debug</term>
        <listitem>
          <para>operate in debug mode</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-o</term>
        <term>--output</term>
        <listitem>
          <para>output file / directory</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-p</term>
        <term>--parser</term>
        <listitem>
          <para>select a parser</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-l</term>
        <term>--link</term>
        <listitem>
          <para>link</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-f</term>
        <term>--formatter</term>
        <listitem>
          <para>select a formatter</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-I</term>
        <listitem>
          <para>set an include search path</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-D</term>
        <listitem>
          <para>specify a macro for the parser</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>-W</term>
        <listitem>
          <para>pass down additional arguments to a processor.
            For example '-Wp,-I.' sends the '-I.' option to the
            parser.</para>
        </listitem>
      </varlistentry>
    </variablelist>
  </appendix>
  <appendix><title>Listing of some Processors and their parameters</title>
    <para>
      This is a listing of all processors with their respective parameters
      that can be set as described in <xref linkend="script" />.
    </para>
    <xi:include href="Synopsis.Parsers.Python.Parser.xml">
      <xi:fallback>The Python parser reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Parsers.IDL.Parser.xml">
      <xi:fallback>The IDL parser reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Parsers.Cpp.Parser.xml">
      <xi:fallback>The Cpp parser reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Parsers.C.Parser.xml">
      <xi:fallback>The C parser reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Parsers.Cxx.Parser.xml">
      <xi:fallback>The Cxx parser reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Processors.Linker.xml">
      <xi:fallback>The Linker reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Processors.MacroFilter.xml">
      <xi:fallback>The MacroFilter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Processors.Comments.Filter.xml">
      <xi:fallback>The Comments.Filter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Processors.Comments.Translator.xml">
      <xi:fallback>The Comments.Translator reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.Dot.Formatter.xml">
      <xi:fallback>The Dot formatter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.Dump.Formatter.xml">
      <xi:fallback>The Dump formatter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.Docbook.Formatter.xml">
      <xi:fallback>The Docbook formatter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.Texinfo.Formatter.xml">
      <xi:fallback>The Texinfo formatter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.HTML.Formatter.xml">
      <xi:fallback>The HTML formatter reference...</xi:fallback>
    </xi:include>
    <xi:include href="Synopsis.Formatters.SXR.Formatter.xml">
      <xi:fallback>The SXR formatter reference...</xi:fallback>
    </xi:include>
  </appendix>
  <appendix>
    <title>Supported documentation markup</title>
    <para>Synopsis can handle a variety of documentation markup through
      markup formatter plugins. The most frequently used markup types are
      built into the framework, and are are available via the 
      <command>synopsis</command> applet. These are <varname>Javadoc</varname>
      (available as <option>--translate=javadoc</option>), as well as
      <varname>ReStructuredText</varname> (available as 
      <option>--translate=rst</option>).</para>
    <section>
      <title>Javadoc</title>
    </section>
    <section>
      <title>Restructured Text</title>
    </section>
  </appendix>
</book>
